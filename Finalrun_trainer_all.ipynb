{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ba92a45-431d-4f9e-bee7-685a07b1e034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: 3.8.10 (default, Sep 28 2021, 16:10:42) \n",
      "[GCC 9.3.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:08:01.481836: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf version: 2.5.0\n",
      "/GPU:0\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Tue Nov 23 01:08:03 2021\n",
      "############ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:08:03.562536: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-11-23 01:08:03.649359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:03:00.0 name: GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2021-11-23 01:08:03.649404: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-11-23 01:08:03.661604: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-11-23 01:08:03.661664: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-11-23 01:08:03.663841: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-23 01:08:03.666600: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-23 01:08:03.675985: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-11-23 01:08:03.678006: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-11-23 01:08:03.678949: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-11-23 01:08:03.682099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import sys\n",
    "print('python: %s' % sys.version)\n",
    "\n",
    "# Make numpy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "print('tf version: %s' % tf.__version__) \n",
    "GPU_device = '/GPU:0'\n",
    "# GPU_device = '/device:GPU:0'\n",
    "# GPU_device = '/physical_device:GPU:0'\n",
    "print(GPU_device)\n",
    "print(tf.config.list_physical_devices(device_type=None))\n",
    "# from tensorflow.compat.v1 import ConfigProto\n",
    "# from tensorflow.compat.v1 import InteractiveSession\n",
    "# config = ConfigProto()\n",
    "# # config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "# session = InteractiveSession(config=config)\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "\n",
    "def print_time():\n",
    "    print(time.asctime(time.localtime(time.time())))\n",
    "    print(12*\"#\",\"\\n\")\n",
    "\n",
    "print_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d483fb74-f325-4c86-b031-39bc979f89d9",
   "metadata": {},
   "source": [
    "# TMD sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff926c21-a1f0-4fe1-ad89-fa796dad8dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/share/TMD_Colab/validation/training/log\n",
      "\n",
      "You have selected: EIC_aff_tmdaff.pkl\n",
      "         pT   Q2         x    z  R0max  R1max  R2max\n",
      "0  0.100000  1.0  0.000062  0.1   0.05   0.05   0.05\n",
      "1  0.193611  1.0  0.000062  0.1   0.05   0.05   0.05\n",
      "2  0.374852  1.0  0.000062  0.1   0.05   0.05   0.05\n",
      "3  0.725756  1.0  0.000062  0.1   0.05   0.05   0.05\n",
      "4  1.405143  1.0  0.000062  0.1   0.05   0.05   0.05\n",
      "0            0.0\n",
      "1            0.0\n",
      "2            0.0\n",
      "3            0.0\n",
      "4            0.0\n",
      "            ... \n",
      "102297595    1.0\n",
      "102297596    1.0\n",
      "102297597    1.0\n",
      "102297598    1.0\n",
      "102297599    1.0\n",
      "Name: tmdaff, Length: 102297600, dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:08:28.152105: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-23 01:08:28.157587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:03:00.0 name: GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2021-11-23 01:08:28.159978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-11-23 01:08:28.160055: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-11-23 01:08:29.003147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-11-23 01:08:29.003187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-11-23 01:08:29.003195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-11-23 01:08:29.006646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22294 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3090, pci bus id: 0000:03:00.0, compute capability: 8.6)\n",
      "2021-11-23 01:08:39.122853: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 5728665600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(7,)\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "CPU times: user 5.3 s, sys: 16.8 s, total: 22.1 s\n",
      "Wall time: 40.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# run setup\n",
    "lable = 'tmdaff'\n",
    "run_name = 'final_TMD'\n",
    "mld_preprocessing_name = './models/tmd_norm_layer' \n",
    "file = 'EIC_aff_tmdaff.pkl'\n",
    "path2Data = '../data/training/'\n",
    "units = 576\n",
    "units2 = 160\n",
    "patience = 50\n",
    "outputlayer = \"sigmoid\" \n",
    "learning_rate = 1e-4\n",
    "batch_size = 7400\n",
    "epochs = 5\n",
    "classes = 1\n",
    "\n",
    "# set up logs\n",
    "working_dir = os.getcwd()\n",
    "log_dir = os.path.join(working_dir, 'log')\n",
    "print(log_dir)\n",
    "if os.path.isdir(log_dir) == 0:\n",
    "    os.mkdir(log_dir)\n",
    "\n",
    "# reading data\n",
    "print('\\nYou have selected:',file)\n",
    "train_features = np.load(path2Data+file, allow_pickle=True)\n",
    "\n",
    "# phrase data\n",
    "train_labels = train_features.pop(lable)\n",
    "print(train_features.head())\n",
    "print(train_labels)\n",
    "print(type(train_features))\n",
    "train_features = tf.convert_to_tensor(train_features)\n",
    "print(type(train_features))\n",
    "train_labels = tf.convert_to_tensor(train_labels)\n",
    "\n",
    "# preprcessing layer\n",
    "input_shape = train_features.shape[1:]\n",
    "print(input_shape)\n",
    "\n",
    "model = keras.models.load_model(mld_preprocessing_name)\n",
    "normalizer = model.layers.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ca5cc98-fc84-4f99-b351-430119d085f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 7)]               0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 7)                 15        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 576)               4608      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 160)               92320     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 161       \n",
      "=================================================================\n",
      "Total params: 97,104\n",
      "Trainable params: 97,089\n",
      "Non-trainable params: 15\n",
      "_________________________________________________________________\n",
      "CPU times: user 49.6 ms, sys: 3.34 ms, total: 53 ms\n",
      "Wall time: 49.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# set up model\n",
    "def get_callbacks(name, patience):\n",
    "    return [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir+'/'+name),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=working_dir+'/checkpoints/'+ name + '_{epoch:02d}-{val_loss:.4f}.ckpt',\n",
    "        save_weights_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='auto',\n",
    "        save_best_only=True),\n",
    "    ]\n",
    "\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "norm = normalizer(inputs)\n",
    "hidden_layer1 = layers.Dense(units, activation=\"relu\")(norm)\n",
    "hidden_layer2 = layers.Dense(units2, activation=\"relu\")(hidden_layer1)\n",
    "outputs = layers.Dense(classes, activation=outputlayer)(hidden_layer2)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# with tf.device(GPU_device):\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44844e65-1610-4de3-9155-787dab3ef954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d089c414-c847-4c19-a38e-54e9acfdd36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 23 01:08:44 2021\n",
      "############ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:08:44.325043: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-11-23 01:08:44.325085: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-11-23 01:08:44.325148: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1611] Profiler found 1 GPUs\n",
      "2021-11-23 01:08:44.329992: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcupti.so.11.2\n",
      "2021-11-23 01:08:44.611763: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-11-23 01:08:44.616036: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n",
      "2021-11-23 01:08:45.847886: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 4582932480 exceeds 10% of free system memory.\n",
      "2021-11-23 01:08:49.335539: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-23 01:08:49.358902: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2294645000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:08:55.588057: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1/11060 [..............................] - ETA: 20:50:26 - loss: 0.2142"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:08:56.980232: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-11-23 01:08:56.980296: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2021-11-23 01:08:57.046742: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-11-23 01:08:57.046771: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   37/11060 [..............................] - ETA: 2:55 - loss: 0.1781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:08:57.428885: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-11-23 01:08:57.430167: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n",
      "2021-11-23 01:08:57.461583: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 76 callback api events and 74 activity events. \n",
      "2021-11-23 01:08:57.464873: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-11-23 01:08:57.487242: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /home/share/TMD_Colab/validation/training/log/final_TMD/train/plugins/profile/2021_11_23_01_08_57\n",
      "2021-11-23 01:08:57.489140: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to /home/share/TMD_Colab/validation/training/log/final_TMD/train/plugins/profile/2021_11_23_01_08_57/precision.trace.json.gz\n",
      "2021-11-23 01:08:57.495210: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /home/share/TMD_Colab/validation/training/log/final_TMD/train/plugins/profile/2021_11_23_01_08_57\n",
      "2021-11-23 01:08:57.495841: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to /home/share/TMD_Colab/validation/training/log/final_TMD/train/plugins/profile/2021_11_23_01_08_57/precision.memory_profile.json.gz\n",
      "2021-11-23 01:08:57.496169: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /home/share/TMD_Colab/validation/training/log/final_TMD/train/plugins/profile/2021_11_23_01_08_57Dumped tool data for xplane.pb to /home/share/TMD_Colab/validation/training/log/final_TMD/train/plugins/profile/2021_11_23_01_08_57/precision.xplane.pb\n",
      "Dumped tool data for overview_page.pb to /home/share/TMD_Colab/validation/training/log/final_TMD/train/plugins/profile/2021_11_23_01_08_57/precision.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /home/share/TMD_Colab/validation/training/log/final_TMD/train/plugins/profile/2021_11_23_01_08_57/precision.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /home/share/TMD_Colab/validation/training/log/final_TMD/train/plugins/profile/2021_11_23_01_08_57/precision.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /home/share/TMD_Colab/validation/training/log/final_TMD/train/plugins/profile/2021_11_23_01_08_57/precision.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11060/11060 [==============================] - 52s 4ms/step - loss: 0.0176 - val_loss: 0.0042\n",
      "Epoch 2/5\n",
      "11060/11060 [==============================] - 44s 4ms/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 3/5\n",
      "11060/11060 [==============================] - 43s 4ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 4/5\n",
      "11060/11060 [==============================] - 44s 4ms/step - loss: 6.7138e-04 - val_loss: 9.6497e-04\n",
      "Epoch 5/5\n",
      "11060/11060 [==============================] - 43s 4ms/step - loss: 5.0115e-04 - val_loss: 6.9338e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:12:36.158528: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/final_TMD/assets\n",
      "model saved\n",
      "Tue Nov 23 01:12:36 2021\n",
      "############ \n",
      "\n",
      "CPU times: user 9min 26s, sys: 1min 51s, total: 11min 18s\n",
      "Wall time: 3min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print_time()\n",
    "# training \n",
    "# with tf.device(GPU_device):\n",
    "model.fit(x=train_features, y=train_labels, validation_split=0.2,\n",
    "          batch_size=batch_size, verbose=1, epochs=epochs,\n",
    "          callbacks=get_callbacks(run_name, patience), shuffle=True)\n",
    "\n",
    "model.save('./models/'+run_name)    \n",
    "print('model saved')\n",
    "print_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e5260b-e31a-4871-900e-fdc5f68e3fed",
   "metadata": {},
   "source": [
    "# Collinear sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e0e8c2b-d63a-4c9a-85b4-3bccdfa013da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/share/TMD_Colab/validation/training/log\n",
      "\n",
      "You have selected: EIC_aff_collinearaff.pkl\n",
      "         pT   Q2         x    z  R0max  R1max  R2max\n",
      "0  0.100000  1.0  0.000062  0.1   0.05   0.05   0.05\n",
      "1  0.193611  1.0  0.000062  0.1   0.05   0.05   0.05\n",
      "2  0.374852  1.0  0.000062  0.1   0.05   0.05   0.05\n",
      "3  0.725756  1.0  0.000062  0.1   0.05   0.05   0.05\n",
      "4  1.405143  1.0  0.000062  0.1   0.05   0.05   0.05\n",
      "0            0.0554\n",
      "1            0.0513\n",
      "2            0.0550\n",
      "3            0.0539\n",
      "4            0.0474\n",
      "              ...  \n",
      "102297595    0.0000\n",
      "102297596    0.0000\n",
      "102297597    0.0000\n",
      "102297598    0.0000\n",
      "102297599    0.0000\n",
      "Name: collinearaff, Length: 102297600, dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:13:01.838119: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 5728665600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(7,)\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "CPU times: user 4.56 s, sys: 15.5 s, total: 20.1 s\n",
      "Wall time: 31.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# run setup\n",
    "lable = 'collinearaff'\n",
    "run_name = 'final_collinear'\n",
    "mld_preprocessing_name = './models/collinear_norm_layer' \n",
    "file = 'EIC_aff_collinearaff.pkl'\n",
    "path2Data = '../data/training/'\n",
    "units = 960\n",
    "units2 = 544\n",
    "patience = 50\n",
    "outputlayer = \"sigmoid\" \n",
    "learning_rate = 1e-4\n",
    "batch_size = 7400\n",
    "epochs = 5\n",
    "classes = 1\n",
    "\n",
    "# set up logs\n",
    "working_dir = os.getcwd()\n",
    "log_dir = os.path.join(working_dir, 'log')\n",
    "print(log_dir)\n",
    "if os.path.isdir(log_dir) == 0:\n",
    "    os.mkdir(log_dir)\n",
    "\n",
    "# reading data\n",
    "print('\\nYou have selected:',file)\n",
    "train_features = np.load(path2Data+file, allow_pickle=True)\n",
    "\n",
    "# phrase data\n",
    "train_labels = train_features.pop(lable)\n",
    "print(train_features.head())\n",
    "print(train_labels)\n",
    "print(type(train_features))\n",
    "train_features = tf.convert_to_tensor(train_features)\n",
    "print(type(train_features))\n",
    "train_labels = tf.convert_to_tensor(train_labels)\n",
    "\n",
    "# preprcessing layer\n",
    "input_shape = train_features.shape[1:]\n",
    "print(input_shape)\n",
    "\n",
    "model = keras.models.load_model(mld_preprocessing_name)\n",
    "normalizer = model.layers.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d657e77f-ddc7-44bd-ac4e-83e6761d8aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 7)]               0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 7)                 15        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 960)               7680      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 544)               522784    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 545       \n",
      "=================================================================\n",
      "Total params: 531,024\n",
      "Trainable params: 531,009\n",
      "Non-trainable params: 15\n",
      "_________________________________________________________________\n",
      "CPU times: user 45.8 ms, sys: 2.89 ms, total: 48.7 ms\n",
      "Wall time: 46.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# set up model\n",
    "def get_callbacks(name, patience):\n",
    "    return [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir+'/'+name),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=working_dir+'/checkpoints/'+ name + '_{epoch:02d}-{val_loss:.4f}.ckpt',\n",
    "        save_weights_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='auto',\n",
    "        save_best_only=True),\n",
    "    ]\n",
    "\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "norm = normalizer(inputs)\n",
    "hidden_layer1 = layers.Dense(units, activation=\"relu\")(norm)\n",
    "hidden_layer2 = layers.Dense(units2, activation=\"relu\")(hidden_layer1)\n",
    "outputs = layers.Dense(classes, activation=outputlayer)(hidden_layer2)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# with tf.device(GPU_device):\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a545afde-7b36-4a0a-b8e8-513a9fd33fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 23 01:13:08 2021\n",
      "############ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:13:08.166882: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-11-23 01:13:08.166931: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-11-23 01:13:08.640408: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-11-23 01:13:08.645141: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n",
      "2021-11-23 01:13:09.762892: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 4582932480 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "    1/11060 [..............................] - ETA: 16:54:00 - loss: 0.1977"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:13:19.579508: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-11-23 01:13:19.579552: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   31/11060 [..............................] - ETA: 4:05 - loss: 0.1327"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:13:20.067885: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-11-23 01:13:20.069541: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n",
      "2021-11-23 01:13:20.099267: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 76 callback api events and 74 activity events. \n",
      "2021-11-23 01:13:20.102255: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-11-23 01:13:20.105172: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /home/share/TMD_Colab/validation/training/log/final_collinear/train/plugins/profile/2021_11_23_01_13_20\n",
      "2021-11-23 01:13:20.107239: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to /home/share/TMD_Colab/validation/training/log/final_collinear/train/plugins/profile/2021_11_23_01_13_20/precision.trace.json.gz\n",
      "2021-11-23 01:13:20.111401: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /home/share/TMD_Colab/validation/training/log/final_collinear/train/plugins/profile/2021_11_23_01_13_20\n",
      "2021-11-23 01:13:20.112102: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to /home/share/TMD_Colab/validation/training/log/final_collinear/train/plugins/profile/2021_11_23_01_13_20/precision.memory_profile.json.gz\n",
      "2021-11-23 01:13:20.112536: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /home/share/TMD_Colab/validation/training/log/final_collinear/train/plugins/profile/2021_11_23_01_13_20Dumped tool data for xplane.pb to /home/share/TMD_Colab/validation/training/log/final_collinear/train/plugins/profile/2021_11_23_01_13_20/precision.xplane.pb\n",
      "Dumped tool data for overview_page.pb to /home/share/TMD_Colab/validation/training/log/final_collinear/train/plugins/profile/2021_11_23_01_13_20/precision.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /home/share/TMD_Colab/validation/training/log/final_collinear/train/plugins/profile/2021_11_23_01_13_20/precision.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /home/share/TMD_Colab/validation/training/log/final_collinear/train/plugins/profile/2021_11_23_01_13_20/precision.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /home/share/TMD_Colab/validation/training/log/final_collinear/train/plugins/profile/2021_11_23_01_13_20/precision.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11060/11060 [==============================] - 56s 5ms/step - loss: 0.0158 - val_loss: 0.0047\n",
      "Epoch 2/5\n",
      "11060/11060 [==============================] - 49s 4ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 3/5\n",
      "11060/11060 [==============================] - 50s 4ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 4/5\n",
      "11060/11060 [==============================] - 50s 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 5/5\n",
      "11060/11060 [==============================] - 50s 4ms/step - loss: 7.5790e-04 - val_loss: 0.0012\n",
      "INFO:tensorflow:Assets written to: ./models/final_collinear/assets\n",
      "model saved\n",
      "Tue Nov 23 01:17:29 2021\n",
      "############ \n",
      "\n",
      "CPU times: user 9min 48s, sys: 2min 2s, total: 11min 50s\n",
      "Wall time: 4min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print_time()\n",
    "# training \n",
    "model.fit(x=train_features, y=train_labels, validation_split=0.2,\n",
    "          batch_size=batch_size, verbose=1, epochs=epochs,\n",
    "          callbacks=get_callbacks(run_name, patience), shuffle=True)\n",
    "    \n",
    "model.save('./models/'+run_name)    \n",
    "print('model saved')\n",
    "print_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5d8344-b9b0-41d2-ac04-48632f7b9716",
   "metadata": {},
   "source": [
    "# current sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb53808c-396b-44d2-9a26-3201968a0866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/share/TMD_Colab/validation/training/log\n",
      "\n",
      "You have selected: EIC_aff_currentaff.pkl\n",
      "         pT   Q2         x    z  R0max  R1max  R2max\n",
      "0  0.100000  1.0  0.000062  0.1   0.05   0.05   0.05\n",
      "1  0.193611  1.0  0.000062  0.1   0.05   0.05   0.05\n",
      "2  0.374852  1.0  0.000062  0.1   0.05   0.05   0.05\n",
      "3  0.725756  1.0  0.000062  0.1   0.05   0.05   0.05\n",
      "4  1.405143  1.0  0.000062  0.1   0.05   0.05   0.05\n",
      "0            0.9689\n",
      "1            0.9682\n",
      "2            0.9656\n",
      "3            0.9701\n",
      "4            0.9676\n",
      "              ...  \n",
      "102297595    1.0000\n",
      "102297596    1.0000\n",
      "102297597    1.0000\n",
      "102297598    1.0000\n",
      "102297599    1.0000\n",
      "Name: currentaff, Length: 102297600, dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:17:44.658086: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 5728665600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(7,)\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "CPU times: user 4.38 s, sys: 16.3 s, total: 20.7 s\n",
      "Wall time: 21.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# run setup\n",
    "lable = 'currentaff'\n",
    "run_name = 'final_current'\n",
    "mld_preprocessing_name = './models/current_norm_layer'\n",
    "file = 'EIC_aff_currentaff.pkl'\n",
    "path2Data = '../data/training/'\n",
    "units = 1024\n",
    "units2 = 112\n",
    "patience = 50\n",
    "outputlayer = \"sigmoid\" \n",
    "learning_rate = 1e-4\n",
    "batch_size = 7400\n",
    "epochs = 5\n",
    "classes = 1\n",
    "\n",
    "# set up logs\n",
    "working_dir = os.getcwd()\n",
    "log_dir = os.path.join(working_dir, 'log')\n",
    "print(log_dir)\n",
    "if os.path.isdir(log_dir) == 0:\n",
    "    os.mkdir(log_dir)\n",
    "\n",
    "# reading data\n",
    "print('\\nYou have selected:',file)\n",
    "train_features = np.load(path2Data+file, allow_pickle=True)\n",
    "\n",
    "# phrase data\n",
    "train_labels = train_features.pop(lable)\n",
    "print(train_features.head())\n",
    "print(train_labels)\n",
    "print(type(train_features))\n",
    "train_features = tf.convert_to_tensor(train_features)\n",
    "print(type(train_features))\n",
    "train_labels = tf.convert_to_tensor(train_labels)\n",
    "\n",
    "# preprcessing layer\n",
    "input_shape = train_features.shape[1:]\n",
    "print(input_shape)\n",
    "\n",
    "model = keras.models.load_model(mld_preprocessing_name)\n",
    "normalizer = model.layers.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cfeee5a-94db-4f56-aad4-ba7d4e3d408f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 7)]               0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 7)                 15        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              8192      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 112)               114800    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 113       \n",
      "=================================================================\n",
      "Total params: 123,120\n",
      "Trainable params: 123,105\n",
      "Non-trainable params: 15\n",
      "_________________________________________________________________\n",
      "CPU times: user 28.4 ms, sys: 8.19 ms, total: 36.6 ms\n",
      "Wall time: 34.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# set up model\n",
    "def get_callbacks(name, patience):\n",
    "    return [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir+'/'+name),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=working_dir+'/checkpoints/'+ name + '_{epoch:02d}-{val_loss:.4f}.ckpt',\n",
    "        save_weights_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='auto',\n",
    "        save_best_only=True),\n",
    "    ]\n",
    "\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "norm = normalizer(inputs)\n",
    "hidden_layer1 = layers.Dense(units, activation=\"relu\")(norm)\n",
    "hidden_layer2 = layers.Dense(units2, activation=\"relu\")(hidden_layer1)\n",
    "outputs = layers.Dense(classes, activation=outputlayer)(hidden_layer2)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# with tf.device(GPU_device):\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48a45996-6255-4dfb-8377-4b329891b40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 23 01:17:50 2021\n",
      "############ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:17:50.848441: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-11-23 01:17:50.848478: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-11-23 01:17:51.357419: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-11-23 01:17:51.361657: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "    1/11060 [..............................] - ETA: 16:37:36 - loss: 0.2388"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:18:06.628555: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-11-23 01:18:06.628602: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   39/11060 [..............................] - ETA: 3:45 - loss: 0.1262  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:18:07.241172: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-11-23 01:18:07.242941: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n",
      "2021-11-23 01:18:07.271947: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 76 callback api events and 74 activity events. \n",
      "2021-11-23 01:18:07.274596: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-11-23 01:18:07.277315: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /home/share/TMD_Colab/validation/training/log/final_current/train/plugins/profile/2021_11_23_01_18_07\n",
      "2021-11-23 01:18:07.279159: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to /home/share/TMD_Colab/validation/training/log/final_current/train/plugins/profile/2021_11_23_01_18_07/precision.trace.json.gz\n",
      "2021-11-23 01:18:07.283167: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /home/share/TMD_Colab/validation/training/log/final_current/train/plugins/profile/2021_11_23_01_18_07\n",
      "2021-11-23 01:18:07.283801: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to /home/share/TMD_Colab/validation/training/log/final_current/train/plugins/profile/2021_11_23_01_18_07/precision.memory_profile.json.gz\n",
      "2021-11-23 01:18:07.284167: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /home/share/TMD_Colab/validation/training/log/final_current/train/plugins/profile/2021_11_23_01_18_07Dumped tool data for xplane.pb to /home/share/TMD_Colab/validation/training/log/final_current/train/plugins/profile/2021_11_23_01_18_07/precision.xplane.pb\n",
      "Dumped tool data for overview_page.pb to /home/share/TMD_Colab/validation/training/log/final_current/train/plugins/profile/2021_11_23_01_18_07/precision.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /home/share/TMD_Colab/validation/training/log/final_current/train/plugins/profile/2021_11_23_01_18_07/precision.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /home/share/TMD_Colab/validation/training/log/final_current/train/plugins/profile/2021_11_23_01_18_07/precision.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /home/share/TMD_Colab/validation/training/log/final_current/train/plugins/profile/2021_11_23_01_18_07/precision.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11060/11060 [==============================] - 49s 4ms/step - loss: 0.0063 - val_loss: 0.0014\n",
      "Epoch 2/5\n",
      " 8196/11060 [=====================>........] - ETA: 9s - loss: 0.0011"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print_time()\n",
    "# training \n",
    "# with tf.device(GPU_device):\n",
    "model.fit(x=train_features, y=train_labels, validation_split=0.2,\n",
    "          batch_size=batch_size, verbose=1, epochs=epochs,\n",
    "          callbacks=get_callbacks(run_name, patience), shuffle=True)\n",
    "    \n",
    "model.save('./models/'+run_name)    \n",
    "print('model saved')\n",
    "print_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9963cc84-eeed-4e45-b7d1-7443e9115f2a",
   "metadata": {},
   "source": [
    "# target sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4644d250-bfb1-48c5-b4a0-f130480e1d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/share/TMD_Colab/validation/training/log\n",
      "\n",
      "You have selected: EIC_aff_targetaff.pkl\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# run setup\n",
    "lable = 'targetaff'\n",
    "run_name = 'final_target'\n",
    "mld_preprocessing_name = './models/target_norm_layer'\n",
    "file = 'EIC_aff_targetaff.pkl'\n",
    "path2Data = '../data/training/'\n",
    "units = 896\n",
    "units2 = 256\n",
    "patience = 50\n",
    "outputlayer = \"sigmoid\" \n",
    "learning_rate = 1e-4\n",
    "batch_size = 7400\n",
    "epochs = 5\n",
    "classes = 1\n",
    "\n",
    "# set up logs\n",
    "working_dir = os.getcwd()\n",
    "log_dir = os.path.join(working_dir, 'log')\n",
    "print(log_dir)\n",
    "if os.path.isdir(log_dir) == 0:\n",
    "    os.mkdir(log_dir)\n",
    "\n",
    "# reading data\n",
    "print('\\nYou have selected:',file)\n",
    "train_features = np.load(path2Data+file, allow_pickle=True)\n",
    "\n",
    "# phrase data\n",
    "train_labels = train_features.pop(lable)\n",
    "print(train_features.head())\n",
    "print(train_labels)\n",
    "print(type(train_features))\n",
    "train_features = tf.convert_to_tensor(train_features)\n",
    "print(type(train_features))\n",
    "train_labels = tf.convert_to_tensor(train_labels)\n",
    "\n",
    "# preprcessing layer\n",
    "input_shape = train_features.shape[1:]\n",
    "print(input_shape)\n",
    "\n",
    "model = keras.models.load_model(mld_preprocessing_name)\n",
    "normalizer = model.layers.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6694f3e8-54ba-4b06-b152-9297672747ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# set up model\n",
    "def get_callbacks(name, patience):\n",
    "    return [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir+'/'+name),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=working_dir+'/checkpoints/'+ name + '_{epoch:02d}-{val_loss:.4f}.ckpt',\n",
    "        save_weights_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='auto',\n",
    "        save_best_only=True),\n",
    "    ]\n",
    "\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "norm = normalizer(inputs)\n",
    "hidden_layer1 = layers.Dense(units, activation=\"relu\")(norm)\n",
    "hidden_layer2 = layers.Dense(units2, activation=\"relu\")(hidden_layer1)\n",
    "outputs = layers.Dense(classes, activation=outputlayer)(hidden_layer2)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# with tf.device(GPU_device):\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1d80f2-38dc-478b-80bb-971d0897ffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print_time()\n",
    "# training \n",
    "model.fit(x=train_features, y=train_labels, validation_split=0.2,\n",
    "          batch_size=batch_size, verbose=1, epochs=epochs,\n",
    "          callbacks=get_callbacks(run_name, patience), shuffle=True)\n",
    "    \n",
    "model.save('./models/'+run_name)    \n",
    "print('model saved')\n",
    "print_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf8f100-8dc0-4b45-894d-e3a5f76c03fe",
   "metadata": {},
   "source": [
    "# Soft sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c5f9f6-6b5e-429a-8ed1-9273031ad1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# run setup\n",
    "lable = 'softaff'\n",
    "run_name = 'final_soft'\n",
    "mld_preprocessing_name = './models/soft_norm_layer' \n",
    "file = 'EIC_aff_softaff.pkl'\n",
    "path2Data = '../data/training/'\n",
    "units = 576\n",
    "units2 = 736\n",
    "patience = 50\n",
    "outputlayer = \"sigmoid\" \n",
    "learning_rate = 1e-4\n",
    "batch_size = 7400\n",
    "epochs = 500\n",
    "classes = 1\n",
    "\n",
    "# set up logs\n",
    "working_dir = os.getcwd()\n",
    "log_dir = os.path.join(working_dir, 'log')\n",
    "print(log_dir)\n",
    "if os.path.isdir(log_dir) == 0:\n",
    "    os.mkdir(log_dir)\n",
    "\n",
    "# reading data\n",
    "print('\\nYou have selected:',file)\n",
    "train_features = np.load(path2Data+file, allow_pickle=True)\n",
    "\n",
    "# phrase data\n",
    "train_labels = train_features.pop(lable)\n",
    "print(train_features.head())\n",
    "print(train_labels)\n",
    "print(type(train_features))\n",
    "train_features = tf.convert_to_tensor(train_features)\n",
    "print(type(train_features))\n",
    "train_labels = tf.convert_to_tensor(train_labels)\n",
    "\n",
    "# preprcessing layer\n",
    "input_shape = train_features.shape[1:]\n",
    "print(input_shape)\n",
    "\n",
    "model = keras.models.load_model(mld_preprocessing_name)\n",
    "normalizer = model.layers.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefd010b-8267-4c39-8eb7-94b4bdc3c799",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# set up model\n",
    "def get_callbacks(name, patience):\n",
    "    return [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir+'/'+name),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=working_dir+'/checkpoints/'+ name + '_{epoch:02d}-{val_loss:.4f}.ckpt',\n",
    "        save_weights_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='auto',\n",
    "        save_best_only=True),\n",
    "    ]\n",
    "\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "norm = normalizer(inputs)\n",
    "hidden_layer1 = layers.Dense(units, activation=\"relu\")(norm)\n",
    "hidden_layer2 = layers.Dense(units2, activation=\"relu\")(hidden_layer1)\n",
    "outputs = layers.Dense(classes, activation=outputlayer)(hidden_layer2)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81da7f39-aba0-4847-99a7-21d00de0be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print_time()\n",
    "# training \n",
    "\n",
    "model.fit(x=train_features, y=train_labels, validation_split=0.2,\n",
    "          batch_size=batch_size, verbose=1, epochs=epochs,\n",
    "          callbacks=get_callbacks(run_name, patience), shuffle=True)\n",
    "    \n",
    "model.save('./models/'+run_name)    \n",
    "print('model saved')\n",
    "print_time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
