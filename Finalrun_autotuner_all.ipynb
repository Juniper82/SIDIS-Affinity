{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e7b852e-a4d5-49fb-99a2-080ef6f86b5f",
   "metadata": {},
   "source": [
    "# preprocessing data for each region and auto tunning \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a967d8c7-c7f1-4404-9b74-70d8b45ffd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-19 07:19:57.660346: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: 3.8.10 (default, Sep 28 2021, 16:10:42) \n",
      "[GCC 9.3.0]\n",
      "tf version: 2.5.0\n",
      "setting log device placement for both gpu and cpu not supported rn\n",
      "/GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-19 07:19:59.489500: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-11-19 07:19:59.530677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:03:00.0 name: GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2021-11-19 07:19:59.530716: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-11-19 07:19:59.534256: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-11-19 07:19:59.534303: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-11-19 07:19:59.535461: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-19 07:19:59.535721: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-19 07:19:59.539155: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-11-19 07:19:59.539925: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-11-19 07:19:59.540076: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-11-19 07:19:59.542404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "#%load_ext tensorboard\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import regularizers\n",
    "import keras_tuner as kt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import time\n",
    "#rm -rf ./logs/\n",
    "\n",
    "print('python: %s' % sys.version)\n",
    "np.random.seed(2206)\n",
    "print('tf version: %s' % tf.__version__) \n",
    "print('setting log device placement for both gpu and cpu not supported rn')\n",
    "# from tensorflow.python.eager import context  \n",
    "# _ = tf.Variable([1])  \n",
    "# context._context = None \n",
    "# context._create_context()  \n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "GPU_devices = tf.config.list_physical_devices('GPU')\n",
    "# GPU_device = '/physical_device:GPU:0'\n",
    "GPU_device = '/GPU:0'\n",
    "print(GPU_device)\n",
    "# CPU_devices = tf.config.list_physical_devices('CPU')\n",
    "# CPU_device = '/physical_device:CPU:0'\n",
    "# print('cpu : ' + '\\n' + str(CPU_devices))\n",
    "# print('gpu ' + '\\n' + str(GPU_devices))\n",
    "# tf.config.experimental.set_memory_growth(GPU_device, True)\n",
    "\n",
    "\n",
    "# print('\\n'*6 + '## configure threads')\n",
    "# print('number of threads between independent operations: %s' % tf.config.threading.get_inter_op_parallelism_threads())\n",
    "# print('number of threads within individual operations parallelism: %s' % tf.config.threading.get_intra_op_parallelism_threads())\n",
    "# import multiprocessing\n",
    "# numCores=multiprocessing.cpu_count()\n",
    "# print(numCores,'cores available')\n",
    "# tf.config.threading.set_inter_op_parallelism_threads(12) \n",
    "# tf.config.threading.set_intra_op_parallelism_threads(12)\n",
    "# tf.config.set_soft_device_placement(True) # tf 2.7\n",
    "# tf.compat.v1.config.set_soft_device_placement(True)\n",
    "# print(tf.config.list_physical_devices(device_type=None))\n",
    "# print('number of threads between independent operations: %s' % tf.config.threading.get_inter_op_parallelism_threads())\n",
    "# print('number of threads within individual operations parallelism: %s' % tf.config.threading.get_intra_op_parallelism_threads())\n",
    "# print('nvidia-smi')\n",
    "#!nvidia-smi    \n",
    "\n",
    "# from tensorflow.python.client import device_lib\n",
    "# custom_objects={\"GlorotUniform\": tf.keras.initializers.glorot_uniform}\n",
    "# print(\"Device Query:\")\n",
    "# print(device_lib.list_local_devices())\n",
    "\n",
    "# print('\\n'*6 + '## testing placement')\n",
    "# _ = tf.Variable([1])  \n",
    "\n",
    "# with tf.device('/device:GPU:0'):\n",
    "#     _ = tf.Variable([1])\n",
    "\n",
    "# with tf.device(\"/device:CPU:0\"):\n",
    "#     _ = tf.Variable([1])\n",
    "    \n",
    "# for muliple gpu workflow\n",
    "# print(tf.config.list_physical_devices(device_type=None))\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "# from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "#set_session(InteractiveSession(config=config))\n",
    "# session = InteractiveSession(config=config)\n",
    "# strategy = tf.distribute.MirroredStrategy() \n",
    "# print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4a8401b-8a22-4ffb-a808-af57ddb32ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 19 07:19:59 2021\n",
      "############ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_time():\n",
    "    print(time.asctime(time.localtime(time.time())))\n",
    "    print(12*\"#\",\"\\n\")\n",
    "\n",
    "print_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2878563e-32a4-4fb4-a222-454ed87ff82a",
   "metadata": {},
   "source": [
    "### Begin TMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "117a0f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/share/TMD_Colab/validation/training\n",
      "['EIC_aff_collinearaff.csv', 'EIC_aff_currentaff.csv', 'EIC_aff_targetaff.csv', 'EIC_aff_tmdaff.csv', 'bigData.csv']\n",
      "EIC_aff_tmdaff.pkl\n",
      "CPU times: user 0 ns, sys: 1.05 ms, total: 1.05 ms\n",
      "Wall time: 753 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(os.getcwd())\n",
    "path2Data = '../data/training/'\n",
    "Files = [file for file in sorted(os.listdir(path2Data)) if file.endswith('.csv')]\n",
    "\n",
    "print(Files)\n",
    "#file = Files[3]\n",
    "file = 'EIC_aff_tmdaff.pkl'\n",
    "print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fdea1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  pT           Q2         x    z  R0max  R1max  R2max\n",
      "0           0.100000     1.000000  0.000062  0.1   0.05   0.05   0.05\n",
      "1           0.193611     1.000000  0.000062  0.1   0.05   0.05   0.05\n",
      "2           0.374852     1.000000  0.000062  0.1   0.05   0.05   0.05\n",
      "3           0.725756     1.000000  0.000062  0.1   0.05   0.05   0.05\n",
      "4           1.405143     1.000000  0.000062  0.1   0.05   0.05   0.05\n",
      "...              ...          ...       ...  ...    ...    ...    ...\n",
      "102297595   2.008343  6536.401637  0.545559  0.9   1.20   1.20   1.20\n",
      "102297596   3.659362  6536.401637  0.545559  0.9   1.20   1.20   1.20\n",
      "102297597   6.667653  6536.401637  0.545559  0.9   1.20   1.20   1.20\n",
      "102297598  12.149000  6536.401637  0.545559  0.9   1.20   1.20   1.20\n",
      "102297599  22.136456  6536.401637  0.545559  0.9   1.20   1.20   1.20\n",
      "\n",
      "[102297600 rows x 7 columns]\n",
      "0            0.0\n",
      "1            0.0\n",
      "2            0.0\n",
      "3            0.0\n",
      "4            0.0\n",
      "            ... \n",
      "102297595    1.0\n",
      "102297596    1.0\n",
      "102297597    1.0\n",
      "102297598    1.0\n",
      "102297599    1.0\n",
      "Name: tmdaff, Length: 102297600, dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-19 07:20:03.743890: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-19 07:20:03.748803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:03:00.0 name: GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2021-11-19 07:20:03.751148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-11-19 07:20:03.751202: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-11-19 07:20:04.590253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-11-19 07:20:04.590306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-11-19 07:20:04.590314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-11-19 07:20:04.593947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22294 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3090, pci bus id: 0000:03:00.0, compute capability: 8.6)\n",
      "2021-11-19 07:20:12.546798: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 5728665600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "CPU times: user 5.17 s, sys: 12.3 s, total: 17.4 s\n",
      "Wall time: 17.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_features = np.load(path2Data+file, allow_pickle=True)\n",
    "#train_features = train_features.drop(columns=['hadron'])\n",
    "train_labels = train_features.pop('tmdaff')\n",
    "print(train_features)\n",
    "print(train_labels)\n",
    "print(type(train_features))\n",
    "train_features = tf.convert_to_tensor(train_features)\n",
    "print(type(train_features))\n",
    "train_labels = tf.convert_to_tensor(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cfdb2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7,)\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "CPU times: user 244 ms, sys: 513 ms, total: 757 ms\n",
      "Wall time: 762 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "input_shape = train_features.shape[1:]\n",
    "print(input_shape)\n",
    "classes = 1\n",
    "model = keras.models.load_model('./models/tmd_norm_layer')\n",
    "normalizer = model.layers.pop(0)\n",
    "# To be used as a normalizing input layer in DNN\n",
    "# normalizer = preprocessing.Normalization(axis=-1)\n",
    "# normalizer.adapt(np.array(train_features))\n",
    "\n",
    "# model = keras.Sequential([normalizer])\n",
    "\n",
    "# model.save('./models/tmd_norm_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf9e944e-f83e-451b-8b00-78daec57b39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "\n",
    "    model = keras.Sequential([normalizer])\n",
    "\n",
    "        \n",
    "    # Tune the number of units in the first Dense layer\n",
    "    # Choose an optimal value between 32-512\n",
    "    hp_units = hp.Int('units', min_value=64, max_value=1024, step=64) # 15 trials\n",
    "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "    # 2nd hidden layer\n",
    "    hp_units2 = hp.Int('units2', min_value=16, max_value=1024, step=48) # 21 trials\n",
    "    model.add(keras.layers.Dense(units=hp_units2, activation='relu')) # m=315 experiments\n",
    "\n",
    "    # add output layer\n",
    "    # activation = hp.Choice(name = 'activation', values = ['softmax', 'sigmoid', 'relu', 'linear'], ordered = False)\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))# activation='relu'),# kernel_initializer='he_uniform')#, activation=\"linear\")\n",
    "    \n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss='mean_squared_error')\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2526ce06-06ad-4843-b4f4-7e489b12a385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 87 Complete [00h 21m 45s]\n",
      "val_loss: 0.00010421664774185047\n",
      "\n",
      "Best val_loss So Far: 0.00010421664774185047\n",
      "Total elapsed time: 06h 37m 39s\n",
      "\n",
      "Search: Running Trial #88\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "units             |832               |576               \n",
      "units2            |400               |160               \n",
      "learning_rate     |0.0001            |0.0001            \n",
      "tuner/epochs      |30                |30                \n",
      "tuner/initial_e...|0                 |0                 \n",
      "tuner/bracket     |0                 |0                 \n",
      "tuner/round       |0                 |0                 \n",
      "\n",
      "Epoch 1/30\n",
      "11060/11060 [==============================] - 52s 4ms/step - loss: 0.0133 - val_loss: 0.0037\n",
      "Epoch 2/30\n",
      "11060/11060 [==============================] - 47s 4ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 3/30\n",
      "11060/11060 [==============================] - 46s 4ms/step - loss: 8.5428e-04 - val_loss: 0.0011\n",
      "Epoch 4/30\n",
      "11060/11060 [==============================] - 46s 4ms/step - loss: 5.1135e-04 - val_loss: 6.8202e-04\n",
      "Epoch 5/30\n",
      "11060/11060 [==============================] - 47s 4ms/step - loss: 3.7782e-04 - val_loss: 5.5026e-04\n",
      "Epoch 6/30\n",
      "10612/11060 [===========================>..] - ETA: 1s - loss: 3.0062e-04"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "log_dir = \"log/autotune_TMD_sigmoid_V6.1/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4)\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=30,\n",
    "                     factor=3,\n",
    "                     directory=log_dir,\n",
    "                     project_name='tmd_auto_tune_final_run')\n",
    "\n",
    "# tuner = kt.RandomSearch(hypermodel=model_builder,\n",
    "#                         objective='val_loss',\n",
    "#                         seed=22,\n",
    "#                         max_trials=100,\n",
    "#                         executions_per_trial=1,\n",
    "#                         directory=log_dir+'/random_search',\n",
    "#                         project_name='tmd_auto_tune_first_layer_complete_dataset')\n",
    "\n",
    "\n",
    "\n",
    "with tf.device(GPU_device):\n",
    "\n",
    "    tuner.search(train_features, train_labels, epochs=30, validation_split=0.2, shuffle = True, batch_size=7400,\n",
    "                callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f546eeb-b814-4e13-8a77-bfcafdeae544",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cd8a7e-bfb3-43f8-b446-b8884f5ebfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "\n",
    "    model = keras.Sequential([normalizer])\n",
    "\n",
    "        \n",
    "    # Tune the number of units in the first Dense layer\n",
    "    # Choose an optimal value between 32-512\n",
    "    hp_units = hp.Int('units', min_value=64, max_value=1024, step=64) \n",
    "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "    # 2nd hidden layer\n",
    "    hp_units2 = hp.Int('units2', min_value=16, max_value=1024, step=48) \n",
    "    model.add(keras.layers.Dense(units=hp_units2, activation='relu')) \n",
    "\n",
    "    # add output layer\n",
    "    # activation = hp.Choice(name = 'activation', values = ['softmax', 'sigmoid', 'relu', 'linear'], ordered = False)\n",
    "    model.add(keras.layers.Dense(1, activation='linear'))# activation='relu'),# kernel_initializer='he_uniform')#, activation=\"linear\")\n",
    "    \n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss='mean_squared_error')\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fd915a-4d41-43e2-b3f4-ea9f5d817d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "log_dir = \"log/autotune_TMD_linear_V6.2/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4)\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=30,\n",
    "                     factor=3,\n",
    "                     directory=log_dir,\n",
    "                     project_name='tmd_auto_tune_final_run')\n",
    "\n",
    "with tf.device(GPU_device):\n",
    "    tuner.search(train_features, train_labels, epochs=30, validation_split=0.2, shuffle = True, batch_size=7400,\n",
    "                callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b651b743-963d-4590-a828-c9c21ef33eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58e466a-3154-4298-a569-32d23d3786d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Begin Collinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c2d63e-643e-4647-bb01-38bb4b618988",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "file = 'EIC_aff_collinearaff.pkl'\n",
    "print('\\nYou have selected:',file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0f7e35-0ace-4c55-afc2-7cb5ad635c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_features = np.load(path2Data+file, allow_pickle=True)\n",
    "\n",
    "train_labels = train_features.pop('collinearaff')\n",
    "print(train_features.head())\n",
    "print(train_labels)\n",
    "print(type(train_features))\n",
    "train_features = tf.convert_to_tensor(train_features)\n",
    "print(type(train_features))\n",
    "train_labels = tf.convert_to_tensor(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d2fd80-9e36-4186-8cf3-710dfa702a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "input_shape = train_features.shape[1:]\n",
    "print(input_shape)\n",
    "classes = 1\n",
    "model = keras.models.load_model('./models/collinear_norm_layer') \n",
    "normalizer = model.layers.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc92ec0-c70e-4af2-8c33-6d89afb113fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "\n",
    "    model = keras.Sequential([normalizer])\n",
    "\n",
    "        \n",
    "    # Tune the number of units in the first Dense layer\n",
    "    # Choose an optimal value between 32-512\n",
    "    hp_units = hp.Int('units', min_value=64, max_value=1024, step=64) \n",
    "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "    # 2nd hidden layer\n",
    "    hp_units2 = hp.Int('units2', min_value=16, max_value=1024, step=48) \n",
    "    model.add(keras.layers.Dense(units=hp_units2, activation='relu')) \n",
    "\n",
    "    # add output layer\n",
    "    # activation = hp.Choice(name = 'activation', values = ['softmax', 'sigmoid', 'relu', 'linear'], ordered = False)\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))# activation='relu'),# kernel_initializer='he_uniform')#, activation=\"linear\")\n",
    "    \n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss='mean_squared_error')\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eb742a-06db-4cc6-85bf-01aeeb0b1ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "log_dir = \"log/autotune_COLLINEAR_sigmoid_V6.1/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4)\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=30,\n",
    "                     factor=3,\n",
    "                     directory=log_dir,\n",
    "                     project_name='collinear_auto_tune_final_run')\n",
    "\n",
    "# tuner = kt.RandomSearch(hypermodel=model_builder,\n",
    "#                         objective='val_loss',\n",
    "#                         seed=22,\n",
    "#                         max_trials=100,\n",
    "#                         executions_per_trial=1,\n",
    "#                         directory=log_dir+'/random_search',\n",
    "#                         project_name='tmd_auto_tune_first_layer_complete_dataset')\n",
    "\n",
    "\n",
    "\n",
    "with tf.device(GPU_device):\n",
    "\n",
    "    tuner.search(train_features, train_labels, epochs=30, validation_split=0.2, shuffle = True, batch_size=7400,\n",
    "                callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8730ff33-d5f0-436b-a45d-537ef1a39fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f076b1a1-27c6-4da7-b5e5-229569e042e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e370331b-6805-462c-a5e7-ae142b6faf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "\n",
    "    model = keras.Sequential([normalizer])\n",
    "\n",
    "        \n",
    "    # Tune the number of units in the first Dense layer\n",
    "    # Choose an optimal value between 32-512\n",
    "    hp_units = hp.Int('units', min_value=64, max_value=1024, step=64) \n",
    "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "    # 2nd hidden layer\n",
    "    hp_units2 = hp.Int('units2', min_value=16, max_value=1024, step=48) \n",
    "    model.add(keras.layers.Dense(units=hp_units2, activation='relu')) \n",
    "\n",
    "    # add output layer\n",
    "    # activation = hp.Choice(name = 'activation', values = ['softmax', 'sigmoid', 'relu', 'linear'], ordered = False)\n",
    "    model.add(keras.layers.Dense(1, activation='linear'))# activation='relu'),# kernel_initializer='he_uniform')#, activation=\"linear\")\n",
    "    \n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss='mean_squared_error')\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821b9fc0-c2fb-4a8f-b37b-1ea105156974",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "log_dir = \"log/autotune_COLLINEAR_linear_V6.2/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4)\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=30,\n",
    "                     factor=3,\n",
    "                     directory=log_dir,\n",
    "                     project_name='collinear_auto_tune_final_run')\n",
    "\n",
    "# tuner = kt.RandomSearch(hypermodel=model_builder,\n",
    "#                         objective='val_loss',\n",
    "#                         seed=22,\n",
    "#                         max_trials=100,\n",
    "#                         executions_per_trial=1,\n",
    "#                         directory=log_dir+'/random_search',\n",
    "#                         project_name='tmd_auto_tune_first_layer_complete_dataset')\n",
    "\n",
    "\n",
    "\n",
    "with tf.device(GPU_device):\n",
    "\n",
    "    tuner.search(train_features, train_labels, epochs=30, validation_split=0.2, shuffle = True, batch_size=7400,\n",
    "                callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3a489b-926d-4f0b-99cc-fb5a29b58897",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d052a7b4-cf01-4511-9490-1ea66d6ed3ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Begin Current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b862eed-942c-49e7-81fd-d06e3a3b6a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "file = 'EIC_aff_currentaff.pkl'\n",
    "print('\\nYou have selected:',file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b3f0cc-fff1-4d1e-895d-05dd297f4537",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_features = np.load(path2Data+file, allow_pickle=True)\n",
    "#train_features = train_features.drop(columns=['hadron'])\n",
    "train_labels = train_features.pop('currentaff')\n",
    "print(train_features)\n",
    "print(train_labels)\n",
    "print(type(train_features))\n",
    "train_features = tf.convert_to_tensor(train_features)\n",
    "print(type(train_features))\n",
    "train_labels = tf.convert_to_tensor(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5254873-6f15-4337-a4b7-6d30c643181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "input_shape = train_features.shape[1:]\n",
    "print(input_shape)\n",
    "classes = 1\n",
    "\n",
    "# To be used as a normalizing input layer in DNN\n",
    "normalizer = preprocessing.Normalization(axis=-1)\n",
    "normalizer.adapt(np.array(train_features))\n",
    "\n",
    "model = keras.Sequential([normalizer])\n",
    "\n",
    "model.save('./models/current_norm_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e600d2bf-a184-4fdf-b40c-b927693d27c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "\n",
    "    model = keras.Sequential([normalizer])\n",
    "\n",
    "        \n",
    "    # Tune the number of units in the first Dense layer\n",
    "    # Choose an optimal value between 32-512\n",
    "    hp_units = hp.Int('units', min_value=64, max_value=1024, step=64) \n",
    "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "    # 2nd hidden layer\n",
    "    hp_units2 = hp.Int('units2', min_value=16, max_value=1024, step=48) \n",
    "    model.add(keras.layers.Dense(units=hp_units2, activation='relu')) \n",
    "\n",
    "    # add output layer\n",
    "    # activation = hp.Choice(name = 'activation', values = ['softmax', 'sigmoid', 'relu', 'linear'], ordered = False)\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))# activation='relu'),# kernel_initializer='he_uniform')#, activation=\"linear\")\n",
    "    \n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss='mean_squared_error')\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39944f37-ae6e-44b5-9f18-8cba89a4e6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "log_dir = \"log/autotune_CURRENT_sigmoid_V6.1/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4)\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=30,\n",
    "                     factor=3,\n",
    "                     directory=log_dir,\n",
    "                     project_name='current_auto_tune_final_run')\n",
    "\n",
    "# tuner = kt.RandomSearch(hypermodel=model_builder,\n",
    "#                         objective='val_loss',\n",
    "#                         seed=22,\n",
    "#                         max_trials=100,\n",
    "#                         executions_per_trial=1,\n",
    "#                         directory=log_dir+'/random_search',\n",
    "#                         project_name='tmd_auto_tune_first_layer_complete_dataset')\n",
    "\n",
    "\n",
    "\n",
    "with tf.device(GPU_device):\n",
    "\n",
    "    tuner.search(train_features, train_labels, epochs=30, validation_split=0.2, shuffle = True, batch_size=7400,\n",
    "                callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a7a90e-ad16-45ba-b01b-467a563c0e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eaa85d-56da-4e99-ab0f-fca9457f8964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "\n",
    "    model = keras.Sequential([normalizer])\n",
    "\n",
    "        \n",
    "    # Tune the number of units in the first Dense layer\n",
    "    # Choose an optimal value between 32-512\n",
    "    hp_units = hp.Int('units', min_value=64, max_value=1024, step=64) \n",
    "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "    # 2nd hidden layer\n",
    "    hp_units2 = hp.Int('units2', min_value=16, max_value=1024, step=48) \n",
    "    model.add(keras.layers.Dense(units=hp_units2, activation='relu')) \n",
    "\n",
    "    # add output layer\n",
    "    # activation = hp.Choice(name = 'activation', values = ['softmax', 'sigmoid', 'relu', 'linear'], ordered = False)\n",
    "    model.add(keras.layers.Dense(1, activation='linear'))# activation='relu'),# kernel_initializer='he_uniform')#, activation=\"linear\")\n",
    "    \n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss='mean_squared_error')\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb592074-7f8e-405e-b875-20ddda6e3883",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "log_dir = \"log/autotune_CURRENT_linear_V6.2/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4)\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=30,\n",
    "                     factor=3,\n",
    "                     directory=log_dir,\n",
    "                     project_name='current_auto_tune_final_run')\n",
    "\n",
    "# tuner = kt.RandomSearch(hypermodel=model_builder,\n",
    "#                         objective='val_loss',\n",
    "#                         seed=22,\n",
    "#                         max_trials=100,\n",
    "#                         executions_per_trial=1,\n",
    "#                         directory=log_dir+'/random_search',\n",
    "#                         project_name='tmd_auto_tune_first_layer_complete_dataset')\n",
    "\n",
    "\n",
    "\n",
    "with tf.device(GPU_device):\n",
    "\n",
    "    tuner.search(train_features, train_labels, epochs=30, validation_split=0.2, shuffle = True, batch_size=7400,\n",
    "                 callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736bc19d-bd12-4161-b921-33986e0d100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a876778-54be-42d5-9577-369606ba1a0e",
   "metadata": {},
   "source": [
    "### Begin Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e963c1a-0a78-4c6d-b28c-35d8316ad955",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "file = 'EIC_aff_targetaff.pkl'\n",
    "print('\\nYou have selected:',file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc5a6e9-413d-4c31-b754-88032822412d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_features = np.load(path2Data+file, allow_pickle=True)\n",
    "#train_features = train_features.drop(columns=['hadron'])\n",
    "train_labels = train_features.pop('targetaff')\n",
    "print(train_features)\n",
    "print(train_labels)\n",
    "print(type(train_features))\n",
    "train_features = tf.convert_to_tensor(train_features)\n",
    "print(type(train_features))\n",
    "train_labels = tf.convert_to_tensor(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b826aff-7504-4112-b82c-2dfa8177aaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "input_shape = train_features.shape[1:]\n",
    "print(input_shape)\n",
    "classes = 1\n",
    "\n",
    "# To be used as a normalizing input layer in DNN\n",
    "normalizer = preprocessing.Normalization(axis=-1)\n",
    "normalizer.adapt(np.array(train_features))\n",
    "\n",
    "model = keras.Sequential([normalizer])\n",
    "\n",
    "model.save('./models/target_norm_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d373f3-30dc-40d8-98c1-1f072cb69a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "\n",
    "    model = keras.Sequential([normalizer])\n",
    "\n",
    "        \n",
    "    # Tune the number of units in the first Dense layer\n",
    "    # Choose an optimal value between 32-512\n",
    "    hp_units = hp.Int('units', min_value=64, max_value=1024, step=64) \n",
    "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "    # 2nd hidden layer\n",
    "    hp_units2 = hp.Int('units2', min_value=16, max_value=1024, step=48)\n",
    "    model.add(keras.layers.Dense(units=hp_units2, activation='relu')) \n",
    "\n",
    "    # add output layer\n",
    "    # activation = hp.Choice(name = 'activation', values = ['softmax', 'sigmoid', 'relu', 'linear'], ordered = False)\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))# activation='relu'),# kernel_initializer='he_uniform')#, activation=\"linear\")\n",
    "    \n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss='mean_squared_error')\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bfbf99-6ccb-4a35-b51a-684b1bb38c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "log_dir = \"log/autotune_TARGET_sigmoid_V6.1/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4)\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=30,\n",
    "                     factor=3,\n",
    "                     directory=log_dir,\n",
    "                     project_name='target_auto_tune_final_run')\n",
    "\n",
    "# tuner = kt.RandomSearch(hypermodel=model_builder,\n",
    "#                         objective='val_loss',\n",
    "#                         seed=22,\n",
    "#                         max_trials=100,\n",
    "#                         executions_per_trial=1,\n",
    "#                         directory=log_dir+'/random_search',\n",
    "#                         project_name='tmd_auto_tune_first_layer_complete_dataset')\n",
    "\n",
    "\n",
    "\n",
    "with tf.device(GPU_device):\n",
    "\n",
    "    tuner.search(train_features, train_labels, epochs=30, validation_split=0.2, shuffle = True, batch_size=7400,\n",
    "                callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dc08c1-f8d8-4c1e-b0b2-5cdef65b3543",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2957942-a640-44ee-a9ad-35c4edf6dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "\n",
    "    model = keras.Sequential([normalizer])\n",
    "\n",
    "        \n",
    "    # Tune the number of units in the first Dense layer\n",
    "    # Choose an optimal value between 32-512\n",
    "    hp_units = hp.Int('units', min_value=64, max_value=1024, step=64)\n",
    "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "    # 2nd hidden layer\n",
    "    hp_units2 = hp.Int('units2', min_value=16, max_value=1024, step=48) \n",
    "    model.add(keras.layers.Dense(units=hp_units2, activation='relu')) \n",
    "\n",
    "    # add output layer\n",
    "    # activation = hp.Choice(name = 'activation', values = ['softmax', 'sigmoid', 'relu', 'linear'], ordered = False)\n",
    "    model.add(keras.layers.Dense(1, activation='linear'))# activation='relu'),# kernel_initializer='he_uniform')#, activation=\"linear\")\n",
    "    \n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss='mean_squared_error')\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a205949d-7199-4913-8ba5-0fbc0fd69580",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "log_dir = \"log/autotune_TARGET_linear_V6.2/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4)\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=30,\n",
    "                     factor=3,\n",
    "                     directory=log_dir,\n",
    "                     project_name='target_auto_tune_final_run')\n",
    "\n",
    "# tuner = kt.RandomSearch(hypermodel=model_builder,\n",
    "#                         objective='val_loss',\n",
    "#                         seed=22,\n",
    "#                         max_trials=100,\n",
    "#                         executions_per_trial=1,\n",
    "#                         directory=log_dir+'/random_search',\n",
    "#                         project_name='tmd_auto_tune_first_layer_complete_dataset')\n",
    "\n",
    "\n",
    "\n",
    "with tf.device(GPU_device):\n",
    "\n",
    "    tuner.search(train_features, train_labels, epochs=30, validation_split=0.2, shuffle = True, batch_size=7400,\n",
    "                callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca42199-3843-437a-8171-b2e65cbcd592",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cc1146-2d0c-4b33-9c62-b32ff7a4e8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fdb124-da55-4972-86b4-b08fdc7a0be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465f3726-6adc-4191-955e-6329185bde04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94047cdd-0455-4215-b4ed-bd3630d116cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc15871-d177-4aa1-b8dd-15b046cdd7c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60522292-d44b-4cf6-a82c-00a9ceed9417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249edcd3-ec7d-41c5-8e88-29ec3ecefb98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb6c225-c621-4854-b06a-52468f70f574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ce6725-b57f-4fb9-aa88-22529438d29f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d4dd4c-1f6f-469b-8790-3e772832fb72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c77e269-d3bd-45fe-b588-14f98d050639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cc361e-8e8a-4934-b046-61d6501b3c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595a45ec-f8f7-4699-a34b-1cd6edd0647d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3cd6fc-f553-4818-a841-c4f01d6e7fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c20710-af4a-469d-aaa2-314cbe7276b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bdb953-9e0b-4e24-ba85-72ebefee1a36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f462a-a4de-4e82-a2dc-03c2e74ffa8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ab7baa-765b-42aa-9d75-61bee2a6d8fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e302bfa-42bc-4e63-9144-f0afe204c202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7375b8-0e22-493d-99a9-d6105b2510bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
